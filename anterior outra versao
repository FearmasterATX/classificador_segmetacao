import cv2 as cv
import numpy as np
import pandas as pd
# Importando o padronizador:
from sklearn.preprocessing import StandardScaler
# Importando o classificador:
from sklearn.svm import SVC


# função mostrar para quando precisarmos ver a imgem
def mostrar(imagem):
    cv.namedWindow('janela', cv.WINDOW_NORMAL)
    cv.imshow('janela', imagem)
    cv.waitKey()
    cv.destroyAllWindows()


# Variaveis
# Vetores que guardarão as informações
(primeiraDMean, primeiraDVar, segundaDMean, segundaDVar,
 terceiraDMean, terceiraDVar) = ([[], [], [], []] for i in np.arange(0, 6))
# variaveis para nomenclatura
primeiroD = ['Luminosity', 'Hue', 'Y', 'Blue']
segundoD = ['Chromatic Coordinate a', 'Saturation', 'Cr', 'Green']
terceiroD = ['Chromatic Coordinate b', 'Value', 'Cb', 'Red']
nomes_dos_formatos = ['Lab', 'HSV', 'YCrCb', 'RGB']
dataframe_da_imgem = [[], [], [], []]  # dataframe a ser classificado
kernel = np.ones((13, 13), np.uint8)  # necessário para filtro morfológico
ordem = ['Luminosity M', 'Luminosity Var', 'Chromatic Coordinate a M', 'Chromatic Coordinate a Var',
         'Chromatic Coordinate b M', 'Chromatic Coordinate b Var', 'Hue M', 'Hue Var', 'Saturation M',
         'Saturation Var', 'Value M', 'Value Var', 'Y M', 'Y Var', 'Cr M', 'Cr Var', 'Cb M', 'Cb Var', 'Blue M',
         'Blue Var', 'Green M', 'Green Var', 'Red M', 'Red Var']
'''
##################################### Treinando o Classificador ################################################
'''
# importando o banco para treino:
treino = pd.read_csv('Banco 3.csv')
treino.sort_values(by='Image', inplace=True, ignore_index=True)
# como o banco tem muita informação vou fazer o corte só das características e das duas classes:
X_treino = treino[ordem]
y1_treino = treino['Class 1']
y2_treino = treino['Class 2']
# Padronizando:
scaler = StandardScaler()
scaler.fit(X_treino)
X_treino = pd.DataFrame(scaler.transform(X_treino), columns=X_treino.columns)
# Definindo os dois classificadores com os melhores hiperparâmetros:
clf1 = SVC(kernel='linear', decision_function_shape='ovo', C=80.5, probability=True)
clf2 = SVC(kernel='linear', decision_function_shape='ovo', C=92.0, probability=True)
# treinando os classificadores:
clf1.fit(X_treino, y1_treino)
clf2.fit(X_treino.loc[y2_treino.dropna().index.tolist()], y2_treino.dropna())
'''
##############################################Segmentação######################################################
'''
nome = input('Digite o nome da imagem contida no diretório: ')
img = cv.imread(nome, 1)  # abrindo a imagem
img = img[1200:2500, 1300:3200]  # recote padrão já pré definido
img2 = cv.cvtColor(img, cv.COLOR_BGR2Lab)
(L, Ca, Cb) = cv.split(img2)  # dividir canal de cores
Cb = cv.blur(Cb, (11, 11))  # blur
opening = cv.morphologyEx(Cb, cv.MORPH_CLOSE, kernel)  # filtro morfológico
t_usado, t_img = cv.threshold(opening, 0, 255, cv.THRESH_BINARY_INV + cv.THRESH_OTSU)  # otsu aplicado na imagem
borda = cv.Canny(t_img, 100, 200)
imgcon, contors, hiera = cv.findContours(borda, cv.RETR_EXTERNAL, cv.CHAIN_APPROX_NONE)  # seleção dos contornos
cnt = contors[0]  # contor da primenira posição da hierarquia
x, y, w, h = cv.boundingRect(cnt)
cv.rectangle(img, (x, y), (x + w, y + h), (0, 0, 0), 2)  # retangulo aproximado a partir dos contornos
roi = img[y + 35:y + h - 35, x + 35:x + w - 35]  # região de interesse

'''
#####################################Extração de caracteristica################################################
'''

cores = [cv.COLOR_BGR2Lab, cv.COLOR_BGR2HSV, cv.COLOR_BGR2YCrCb, 1]
for formatos in range(4):
    # os valores de média e variancia de cada canal de cor é calculado e salvo em um vetor
    dimensoes = cv.cvtColor(roi, cores[formatos])  # os flags daqui tem que ser BGR2algo
    (primeiro, segundo, terceiro) = cv.split(dimensoes)
    # média
    primeiraDMean[formatos].append(np.mean(primeiro))
    segundaDMean[formatos].append(np.mean(segundo))
    terceiraDMean[formatos].append(np.mean(terceiro))
    # variância
    primeiraDVar[formatos].append(np.var(primeiro))
    segundaDVar[formatos].append(np.var(segundo))
    terceiraDVar[formatos].append(np.var(terceiro))
# salvando dados em um dataframe
vetor = [[]]
for a in range(4):
    vetor[0].extend(np.array([primeiraDMean, primeiraDVar, segundaDMean,
                              segundaDVar, terceiraDMean, terceiraDVar]).reshape((6, 4))[:, a])

'''
##################################### Classificação ################################################
'''
v = scaler.transform(vetor)
classe1, classe2 = clf1.predict(v), clf2.predict(v)
prob1, prob2 = clf1.predict_proba(v), clf2.predict_proba(v)
'''
############################# Mensagens de erro ou printando o resultado #############################
'''
dic = dict(
    [((a, b), 0) for a in [250, 500, 1000, 1500, 2000] for b in ['250-500', '500-1000', '1000-1500', '1500-2000']])
erros = [(250, '500-1000'), (250, '1000-1500'), (250, '1500-2000'), (500, '1000-1500'),
         (500, '1500-2000'), (1000, '250-500'), (1000, '1500-2000'), (1500, '250-500'),
         (1500, '500-1000'), (2000, '250-500'), (2000, '500-1000'), (2000, '1000-1500')]
for err in erros:
    dic[err] = 'O algoritmo encontrou uma inconsistência na classificação.\nPor favor tente novamente.'
if dic[(classe1[0], classe2[0])] != 0:
    print(dic[(classe1[0], classe2[0])])
elif prob1.max() < 0.6 and prob2.max() < 0.6:
    print('O algortimo não está seguro na classificação. Por favor tente denovo')
    print('Classificação 1: ' + str(classe1[0]))
    print('Classificação 2: ' + str(classe2[0]))
else:
    print('Classificação 1: ' + str(classe1[0]))
    print('Classificação 2: ' + str(classe2[0]))
